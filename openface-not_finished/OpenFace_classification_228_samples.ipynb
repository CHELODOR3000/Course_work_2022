{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path  \n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'C:\\Users\\User\\Downloads\\RealLifeDeceptionDetection.2016\\Real-life_Deception_Detection_2016\\Frames\\Openface_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 185/238 [00:26<00:08,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_truth_033.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 187/238 [00:27<00:08,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_truth_034.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 193/238 [00:28<00:06,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_truth_037.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:33<00:00,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 1316) (228,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_openface_dataset(data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in tqdm(os.listdir(data_dir)):\n",
    "        fn=os.path.splitext(filename)[0] # goes through files names without extension\n",
    "        if 'of_details' not in fn:\n",
    "            # filenames.append(fn)\n",
    "            openface_df = pd.read_csv(os.path.join(data_dir,filename))\n",
    "            # fill zeroes with mean values where openface failed to detect faces \n",
    "            openface_df.loc[openface_df[' success'] == 0] = openface_df.loc[openface_df[' success'] == 0].replace(0, openface_df.loc[openface_df[' success'] == 1].mean())\n",
    "            # remove some irrelevant columns\n",
    "            openface_df = openface_df.loc[:, ~openface_df.columns.isin(['frame', ' face_id', ' timestamp', ' confidence', ' success'])]\n",
    "\n",
    "            upper_half_df = openface_df.iloc[:len(openface_df) // 2]\n",
    "            lower_half_df = openface_df.iloc[len(openface_df) // 2:len(openface_df)]\n",
    "            halves_df = [upper_half_df, lower_half_df]\n",
    "\n",
    "            for i in halves_df:\n",
    "                total_features=None\n",
    "                mean_features = (np.mean(i, axis=0))\n",
    "                std_features = (np.std(i, axis=0))\n",
    "                max_features = (np.max(i, axis=0))\n",
    "                min_features = (np.min(i, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "                \n",
    "                is_nan = False\n",
    "                for j in range(len(total_features)):\n",
    "                    if np.isnan(total_features[j]):\n",
    "                        is_nan = True\n",
    "                \n",
    "                if is_nan == False and total_features is not None:\n",
    "                    x.append(total_features)\n",
    "                    if filename[6:11] == 'truth':\n",
    "                        y.append(1)\n",
    "                    else:\n",
    "                        y.append(0)\n",
    "                    # print(filename + '_' + i)\n",
    "                    filenames.append(fn)\n",
    "\n",
    "            if is_nan == True:\n",
    "                print(filename)\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,filenames\n",
    "\n",
    "X, y, filenames = create_openface_dataset(os.path.join(DATA_DIR))\n",
    "# x_test, y_test = create_openface_dataset(os.path.join(DATA_DIR, 'Val_AFEW'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial_truth_033, trial_truth_034, trial_truth_037 - files with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openface Train/Test Split with data leak check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All names have a pair\n"
     ]
    }
   ],
   "source": [
    "all_doubles = True\n",
    "for i in range(len(filenames)):\n",
    "    if i % 2 == 1:\n",
    "        if filenames[i] != filenames[i-1]:\n",
    "            all_doubles = False\n",
    "            print(filenames[i-1])\n",
    "\n",
    "if all_doubles == True:\n",
    "    print('All names have a pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X) == len(y) == len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_united = []\n",
    "y_united = []\n",
    "filenames_united = []\n",
    "counter = 0\n",
    "for i in range(len(X)):\n",
    "    if i % 2 != 0:\n",
    "        X_united.append(np.array([X[i-1], X[i]]))\n",
    "        y_united.append(np.array([y[i-1], y[i]]))\n",
    "        filenames_united.append(np.array([filenames[i-1], filenames[i]]))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[-0.33519394  0.24029782 -0.90844565 ...  1.          0.\n",
      "   1.        ]\n",
      " [-0.33873423  0.22622251 -0.91095667 ...  1.          0.\n",
      "   1.        ]\n",
      " [-0.30352965  0.30097358 -0.89948478 ...  1.          0.\n",
      "   1.        ]\n",
      " [-0.30048499  0.29519414 -0.90244767 ...  1.          0.\n",
      "   1.        ]]\n",
      "X_united [array([[-0.33519394,  0.24029782, -0.90844565, ...,  1.        ,\n",
      "         0.        ,  1.        ],\n",
      "       [-0.33873423,  0.22622251, -0.91095667, ...,  1.        ,\n",
      "         0.        ,  1.        ]]), array([[-0.30352965,  0.30097358, -0.89948478, ...,  1.        ,\n",
      "         0.        ,  1.        ],\n",
      "       [-0.30048499,  0.29519414, -0.90244767, ...,  1.        ,\n",
      "         0.        ,  1.        ]])]\n"
     ]
    }
   ],
   "source": [
    "print('X', X[:4])\n",
    "print('X_united', X_united[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y [0 0 0 0]\n",
      "y_united [array([0, 0]), array([0, 0])]\n"
     ]
    }
   ],
   "source": [
    "print('y', y[:4])\n",
    "print('y_united', y_united[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_united_shuffled, y_united_shuffled, filenames_united_shuffled = utils.shuffle(X_united, y_united, filenames_united)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0]),\n",
       " array([1, 1]),\n",
       " array([0, 0]),\n",
       " array([1, 1]),\n",
       " array([1, 1]),\n",
       " array([1, 1]),\n",
       " array([1, 1]),\n",
       " array([0, 0]),\n",
       " array([0, 0]),\n",
       " array([0, 0])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_united_shuffled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['trial_lie_019', 'trial_lie_019'], dtype='<U13'),\n",
       " array(['trial_truth_020', 'trial_truth_020'], dtype='<U15'),\n",
       " array(['trial_lie_025', 'trial_lie_025'], dtype='<U13'),\n",
       " array(['trial_truth_044', 'trial_truth_044'], dtype='<U15'),\n",
       " array(['trial_truth_032', 'trial_truth_032'], dtype='<U15'),\n",
       " array(['trial_truth_012', 'trial_truth_012'], dtype='<U15'),\n",
       " array(['trial_truth_050', 'trial_truth_050'], dtype='<U15'),\n",
       " array(['trial_lie_014', 'trial_lie_014'], dtype='<U13'),\n",
       " array(['trial_lie_028', 'trial_lie_028'], dtype='<U13'),\n",
       " array(['trial_lie_018', 'trial_lie_018'], dtype='<U13')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_united_shuffled[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_united = X_united_shuffled[:82]\n",
    "y_train_united = y_united_shuffled[:82]\n",
    "train_filenames_united = filenames_united_shuffled[:82]\n",
    "x_test_united = X_united_shuffled[len(x_train_united):]\n",
    "y_test_united = y_united_shuffled[len(y_train_united):]\n",
    "test_filenames_united = filenames_united_shuffled[len(train_filenames_united):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "train_filenames = []\n",
    "\n",
    "for i in range(len(x_train_united)):\n",
    "    for j in range(len(x_train_united[i])):\n",
    "        x_train.append(x_train_united[i][j])\n",
    "        y_train.append(y_train_united[i][j])\n",
    "        train_filenames.append(train_filenames_united[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "test_filenames = []\n",
    "\n",
    "for i in range(len(x_test_united)):\n",
    "    for j in range(len(x_test_united[i])):\n",
    "        x_test.append(x_test_united[i][j])\n",
    "        y_test.append(y_test_united[i][j])\n",
    "        test_filenames.append(test_filenames_united[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.35708296,  0.28857529, -0.88456584, ...,  1.        ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.36232963,  0.3030747 , -0.87831   , ...,  1.        ,\n",
       "          0.        ,  1.        ]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_united[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.35708296,  0.28857529, -0.88456584, ...,  1.        ,\n",
       "         0.        ,  1.        ]),\n",
       " array([-0.36232963,  0.3030747 , -0.87831   , ...,  1.        ,\n",
       "         0.        ,  1.        ])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "c = list(set(train_filenames) & set(test_filenames))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сommon train and test elements were not found. The data leak is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.91304348 0.86956522 1.         1.\n",
      " 0.95652174 1.         0.95454545 1.        ]\n",
      "0.97 accuracy with a standard deviation of 0.04\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False)\n",
    "scores = cross_val_score(xgb_clf, X, y, cv=StratifiedKFold(10))\n",
    "print(scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.91304348 1.         1.         1.\n",
      " 0.95652174 1.         0.90909091 1.        ]\n",
      "0.98 accuracy with a standard deviation of 0.04\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier(n_estimators = 1000)\n",
    "scores = cross_val_score(rfc_clf, X, y, cv=10)\n",
    "print(scores)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
